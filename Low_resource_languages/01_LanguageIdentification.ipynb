{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language identification for regional languages of France  \n",
        "\n",
        "In this lab, you will work on varities on French and on the task of language identification."
      ],
      "metadata": {
        "id": "7fVe_50Qz_hA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install libraries and import data"
      ],
      "metadata": {
        "id": "OQgesTgWR9Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext==0.9.2"
      ],
      "metadata": {
        "id": "vwY83JNqfPPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wEaInkNbsen"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import fasttext as ft\n",
        "from huggingface_hub import hf_hub_download\n",
        "import numpy as np\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folder called 'data'\n",
        "!mkdir data\n",
        "# download document available at https://seafile.unistra.fr/f/a6246a7152d44122b957/?dl=1 and store it in the folder you just created\n",
        "!wget --output-document data/parable_dataset.csv -P data https://seafile.unistra.fr/f/a6246a7152d44122b957/?dl=1"
      ],
      "metadata": {
        "id": "CalngBgjb5K4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ce88cf-c5e5-4645-e188-411ce67ab484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-23 08:59:32--  https://seafile.unistra.fr/f/a6246a7152d44122b957/?dl=1\n",
            "Resolving seafile.unistra.fr (seafile.unistra.fr)... 77.72.44.41\n",
            "Connecting to seafile.unistra.fr (seafile.unistra.fr)|77.72.44.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://seafile.unistra.fr/seafhttp/files/98184606-23df-47a1-8ecc-f3d28e6baef9/parable_dataset.csv [following]\n",
            "--2025-01-23 08:59:33--  https://seafile.unistra.fr/seafhttp/files/98184606-23df-47a1-8ecc-f3d28e6baef9/parable_dataset.csv\n",
            "Reusing existing connection to seafile.unistra.fr:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439717 (429K) [application/octet-stream]\n",
            "Saving to: ‘data/parable_dataset.csv’\n",
            "\n",
            "parable_dataset.csv 100%[===================>] 429.41K   916KB/s    in 0.5s    \n",
            "\n",
            "2025-01-23 08:59:34 (916 KB/s) - ‘data/parable_dataset.csv’ saved [439717/439717]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now have access to the file `parable_dataset.csv` in the folder `data`. Some explanations about this dataset:"
      ],
      "metadata": {
        "id": "kPiXFBwqSEL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of the dataset\n",
        "\n",
        "The dataset has been acquired from a book entitled [\"Parabole de l'enfant prodigue en divers dialectes, patois de la France, avec une introduction sur la formation des dialectes et patois de la France\"](https://archive.org/details/paraboledelenfan00favr/), published in 1879 and authored by Léopold Favre.\n",
        "It contains translations of the \"Parable of the Lost Son\" in several regional languages of France, collected at the beginning of the 19th century.\n",
        "\n",
        "The dataset presents a combination of challenges which are often observed in low-resource settings:\n",
        "- diachronic variation\n",
        "- diatopic variation\n",
        "- lack of spelling standards\n",
        "- errors due to OCR (Optical Charactacter Recognition)\n",
        "- approximate characterization of the language due to the lack of dedicated ISO 639.3 codes."
      ],
      "metadata": {
        "id": "-ouPeyK4R0nT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Exploration of the dataset"
      ],
      "metadata": {
        "id": "Q9rcNnn_g0rP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Load the parable dataset into a pandas DataFrame object called `parable_df`. Also print the shape of the dataset, its columns, the five first rows and the five last rows.**"
      ],
      "metadata": {
        "id": "KK-ZPs_6TD2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "3FPmKxZfTRJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Print all the verses of the version whose title is `\"Parabole de l'Enfant prodigue. Evangile selon Saint-Luc, chap. XV. (Traduction de Le Maistre de Sacy.)\"`. If you are a French speaker, you should be able to understand it (even if some sentences \"feel old\").**"
      ],
      "metadata": {
        "id": "XIhz7uqDUge2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_1 = \"Parabole de l'Enfant prodigue. Evangile selon Saint-Luc, chap. XV. (Traduction de Le Maistre de Sacy.)\"\n",
        "\n",
        "# TO DO"
      ],
      "metadata": {
        "id": "YOG7vW3EXGtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Now print all the verses of the version whose title is `Id. en patois d'Onville, canton de Gorze (Moselle)\"`. Can you understand it this time ? Which variety is it ? Which language ?**\n",
        "\n"
      ],
      "metadata": {
        "id": "_hmOvecaVbd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_2 = \"Id. en patois d'Onville, canton de Gorze (Moselle)\"\n",
        "\n",
        "# TO DO"
      ],
      "metadata": {
        "id": "syD0pWseV9ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Now we'll have a look at the different varities and languages contained in the dataset. Print the list of all varieties contained in the dataset, and the list of all languages.**"
      ],
      "metadata": {
        "id": "69zJDNPuhhbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "cjGLRh9Ph4PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should find 16 varities, and 7 languages, Occitan being the most represented.\n",
        "\n",
        "\n",
        "Note that there are 3 types of relations between a variety and a language:\n",
        "- `dialect`: the variety is considered to be a dialect of the corresponding language\n",
        "- `match`: the variety and the language match, meaning that this is considered to be an independent language\n",
        "- `same_macro_language`: the variety is not a dialect of the language, but they have the same macro language. For instance, \"Bourguignon-Morvandiau\" is not a dialect of French, but both \"Bourguignon-Morvandiau\" and \"French\" are both \"Langues d'oïl\"."
      ],
      "metadata": {
        "id": "eNKIgeSNgu0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5) Which varieties are considered a dialect of a given language, according to the `var_lang_rel` column ?**"
      ],
      "metadata": {
        "id": "ngNnuKQbW6LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "fWjit71LXVpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Which varieties are considered as independant languages, according to the `var_lang_rel` column ?**"
      ],
      "metadata": {
        "id": "No0eSRe-XWHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "1ZMZD7p-X0DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7) Which varieties share a macro language with the corresponding languages, according to the `var_lang_rel` column ?**"
      ],
      "metadata": {
        "id": "JlggjVdPYXRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "LBlUafohYjvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that:\n",
        "- Franc-Comtois is spoken in the Franche-Comté region and some cantons in Switzerland\n",
        "- Poitevin-Saintongeais is spoken in central Western France\n",
        "- Lorrain Roman is spoken in Lorraine\n",
        "- Normand is spoken in Normandy\n",
        "- Bourguignon-Morvandiau is spoken in Burgundy"
      ],
      "metadata": {
        "id": "f6OmIU85ltls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Language identification\n"
      ],
      "metadata": {
        "id": "uhHTzd-rod6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1  \n",
        "Try the following language identification tools on the dataset (1 verse = 1 prediction):\n",
        "  - Language identification tools:\n",
        "    - GlotLID (v2 and v3) : https://github.com/cisnlp/GlotLID (v2 and v3)\n",
        "    - OpenLID (v2) : https://huggingface.co/laurievb/OpenLID-v2\n",
        "    - fastText : https://huggingface.co/facebook/fasttext-language-identification  \n",
        "\n",
        "You can store the predicted labels and confidence scores directly as columns of the dataset for each model (e.g in columns `glotlid_2_preds` and `glotlid_2_scores` for model glotlid_2). Then, answer the following questions:\n",
        "  -  Which model obtains the best overal results (in terms of precision, recall, f-measure) ? You can compute scores for each of the languages contained in the dataset. Hint : consider using `sklearn.metrics.classifiction_report`.\n",
        "  -  Which model has the largest coverage of the languages in the dataset ?\n",
        "\n",
        "In case you need a little help to get started, here are some directions on how to load and use the first model **glotlid_v2**:"
      ],
      "metadata": {
        "id": "x2v8KEdnc7SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use this function to load the different models\n",
        "def load_model(model_name, file_name):\n",
        "    model_path = hf_hub_download(repo_id=model_name, filename=file_name)\n",
        "    model = ft.load_model(model_path)\n",
        "    return model\n",
        "\n",
        "# Source information on GlotLID models: https://huggingface.co/cis-lmu/glotlid\n",
        "# v1: introduced in the GlotLID paper and used in all experiments.\n",
        "# v2: an edited version of v1, featuring more languages, and cleaned from noisy corpora based on the analysis of v1\n",
        "# v3: an edited version of v2, featuring more languages, excluding macro languages, further cleaned from noisy corpora\n",
        "# and incorrect metadata labels based on the analysis of v2, supporting \"zxx\" and \"und\" series labels\n",
        "\n",
        "# Load the glotlid_v2 model\n",
        "# check the model's documentation to find the values of model_name and file_name\n",
        "model_name = \"cis-lmu/glotlid\"\n",
        "file_name = \"model_v2.bin\"\n",
        "glotlid_2 = load_model(model_name = model_name, file_name = file_name)"
      ],
      "metadata": {
        "id": "XNOI1rzUmQIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the model on a few example sentences to understand the type of predictions returned\n",
        "print(glotlid_2.predict(\"Hello, how are you today?\"))\n",
        "print(glotlid_2.predict(\"Bonjour à tous et à toutes, j'espère que vous allez bien\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o4AuwfymwFx",
        "outputId": "a919c24a-9688-4ee0-ddc8-650c6db0007a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('__label__eng_Latn',), array([0.99998987]))\n",
            "(('__label__fra_Latn',), array([0.99996352]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "CTp5al71bY3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2  \n",
        " Display the confusion matrix for each model to analyse the most frequent confusions. Do they make sense from a linguistic point-of-view?  \n",
        "* Consider using `sklearn.metrics.confusion_matrix` and `sns.heatmap` for a nicer display. As you will find that the models sometimes predict labels outside of the target languages, you can have a column in your confusion matrix named `other`. Once you succeeded, you can also plot a more detailed version of the confusion matrix including columns of other languages commonly predicted by the models (e.g. the top 15)."
      ],
      "metadata": {
        "id": "Z7USHYgAbZtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "ZZTN7oYxcP4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3  \n",
        "Analyse the results obtained for the Occitan dialects. Are some dialects better classified as others?"
      ],
      "metadata": {
        "id": "c5m1bN5PeRAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "c2xujZIeecjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4  \n",
        "\n",
        "Write a synthesis of your observations: which tool would you recommend using in this setting, if any? What are the main advantages and disadvantages of each tool?"
      ],
      "metadata": {
        "id": "1VAakejIeWI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Done early ?\n",
        "\n",
        "If you're done early, here are some additionnal questions that you can consider:  \n",
        "\n",
        "\n",
        "*   Until now, we have considered the performance of models separately. Is it possible to improve the results by using a majority vote strategy ? or a strategy where we favor the model with highest confidence on a given verse ?\n",
        "*   Until now, we have performed language identification verse by verse. But can we better recognise language by predicting the language of an entire version of the parable of the Lost Son ?  \n",
        "* Have a look at the predictions with very low model certainty. Do they correspond to unsupported models or poorly predicted languages ?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wdATHqtnA0qq"
      }
    }
  ]
}